\Chapter{CONCLUSION}\label{sec:Conclusion}


% On résume ici le contenu du mémoire
% relevons ses limites et proposons des pistes pour les surmonter


%%
%%  SYNTHESE DES TRAVAUX / SUMMARY OF WORKS
%%
\section{Synthèse des travaux}


Dans ce travail, nous nous sommes intéressés au %on s'est intéressé au 
problème de l'extraction de taxonomie à partir d'un graphe de connaissance. Plus particulièrement, notre idée était d'utiliser les plongements vectoriels issus d'un graphe de connaissance pour identifier des groupes d'entités cohérents, et établir des liens taxonomiques entre ces groupes. L'objectif est donc d'établir une hiérarchie entre les classes existantes, mais aussi de pouvoir découvrir et caractériser de nouvelles classes. 

Pour cela, nous commençons par une étude des modèles de plongement vectoriel, sous l'angle de la \textit{séparabilité} : nous mesurons la capacité des modèles de plongement à plonger des entités de types différents dans des régions différentes de l'espace. % Sur cette tâche, la hiérarchie entre les modèles n'est pas celle que l'on obtient sur les tâches d'évaluation usuelles.
%
Cette tâche permet de nuancer l'état de l'art en matière de plongements vectoriels : en effet, sur les tâches d'évaluation usuelles que sont la prédiction de liens ou la complétion de triplets, TransE obtient des performances inférieures à des modèles plus expressifs comme ComplEx; ici, la situation est inversée.


Nous abordons ensuite le problème de l'extraction de taxonomie à partir d'un graphe de connaissance, en se basant sur DBpedia. Puisque l'on veut pouvoir identifier de nouvelles classes, on se base sur un regroupement non-supervisé des plongements vectoriels : cela nous permet d'extraire une structure d'arbre sur les groupes d'entités sans aucune supervision. À partir de cette structure, on peut décliner l'approche pour obtenir une taxonomie expressive ou non-expressive.

%si l'on injecte une liste de types connus
Si l'on fait correspondre ces groupes à des types connus, on obtient une taxonomie sur ces types. Au chapitre \ref{chap:te}, nous proposons deux méthodes pour établir cette correspondance, l'une qui détermine une injection optimale des types vers les groupes, l'autre qui propose une association multiple entre les uns et les autres. Nous montrons que ces deux méthodes sont capables d'égaler et même de dépasser une méthode basée sur un regroupement supervisé.

Au chapitre \ref{chap:texp}, on associe au contraire les groupes à des axiomes logiques expressifs, et on ajoute un mécanisme d'itération pour fiabiliser le résultat : d'une part, le regroupement hiérarchique est répété sur des groupes d'entités de plus en plus spécifiques, et d'autre part la taxonomie extraite est étendue petit à petit sur la base de ce regroupement. Nous obtenons ainsi une taxonomie expressive de DBpedia.


% Au-delà de l'extraction de taxonomie proprement dite, ce travail nous permet d'évaluer les modèles de plongement; la hiérarchie obtenue entre les modèles re

%met en perspective les résultats

%d'une part, la hiérarchie que nous obtenons entre modèles n'est pas celle obtenue sur les tâches d'évaluation usuelles; d'autre part, 


\section{Limites et pistes d'améliorations}

Nous identifions ici quelques limites des travaux présentés ici, et proposons des pistes pour les surmonter. Nous esquissons aussi des directions de recherche pour poursuivre ou prolonger le travail entamé dans ce mémoire.


\paragraph{Modèles de plongement}

Dans tous les travaux présentés ici, on s'est restreint à évaluer six modèles de plongement, entraînés avec les hyperparamètres par défaut. Augmenter le nombre de modèles entraînés et faire varier ces hyperparamètres constitue donc une première piste pour affiner et systématiser les résultats obtenus, à la fois pour la séparabilité et l'extraction de taxonomie. 

Sur la question des hyperparamètres, \cite{kadlec2017knowledge} a montré que la recherche d'hyperparamètres était une étape cruciale pour la tâche de prédiction de lien; si cette conclusion s'applique également à l'extraction de taxonomie, alors une recherche rigoureuse d'hyperparamètres s'impose : non seulement pour obtenir les meilleurs résultats possibles, mais aussi pour comprendre l'interaction entre les choix de modélisation effectués par un modèle de plongement donné, les valeurs des différents hyperparamètres et les données d'entrée. 
% Cela permettrait de mieux comprendre . 
% pour expliquer quelle part de la variabilité des résultats d'un modèle à l'autre s'explique par les choix d'hyperparamètres ou les propriétés intrinsèques des modèles.

Quant aux modèles de plongement, de nombreuses approches ont été proposées qui obtiennent de bons résultats sur les jeux d'évaluation usuelles. Dans la lignée des modèles présentés ici, on peut citer des modèles algébriques comme HolE \cite{hole2016} et SimplE \cite{simple2018}, des modèles géométriques, comme PTransE \cite{ptranse} qui étend TransE à des chemins dans le graphe, plutôt qu'à des triplets isolés, ou RotatE \cite{rotate2019}, qui choisit de représenter les relations par des rotations dans l'espace. D'autres approches incluent des modèles neuronaux, comme R-GCN \cite{rgcn2018}, ProjE \cite{proje2017} ou ConvE \cite{conve2018}, ou l'utilisation de géométries non-euclidiennes \cite{nickel2017poincare, nickel2018learning}.

Pour l'évaluation des modèles, qui fait l'objet du chapitre \ref{chap:kge}, notre tâche de séparabilité se révèle incomplète : idéalement, on souhaiterait trouver un mode d'évaluation qui reflète les performances des modèles sur l'extraction taxonomique. Or, RDF2Vec obtient de meilleurs résultats que TransE pour la séparabilité, alors que TransE est supérieur à RDF2Vec sur la tâche d'extraction.  
Pour remédier à ce problème, on pourrait adjoindre une tâche de \textit{regroupement} à la tâche de séparabilité, pour vérifier le comportement des modèles de plongement vis-à-vis des algorithmes de regroupement. 
On peut par exemple tirer des entités appartenant à $k$ classes différentes, puis appliquer un algorithme des $k$-moyennes sur les plongements de ces entités, et finalement mesurer si le partitionnement obtenu recoupe bien les $k$ classes initiales.

\paragraph{Extraction de taxonomie non-expressive}

Notre approche pour l'extraction automatique de taxonomie non-expressive est limitée par l'étape de regroupement. Pour des questions de performance, la taille des données à regrouper est limitée, ce qui, d'une part, empêche d'utiliser l'intégralité des entités du graphe, et d'autre part, entraîne la décroissance exponentielle du nombre d'entités par classe. Ces deux facteurs compliquent le traitement des classes rares ou très spécifiques. En l'état, notre méthode n'est donc pas applicable à tout le graphe DBpedia.

Une solution possible consisterait à itérer la méthode MLM avec des données d'entrée tirées aléatoirement dans le graphe : à chaque étape, on tire des entités aléatoirement, on les regroupe, et on calcule la probabilité des axiomes de subsumption. On peut alors maintenir une matrice contenant ces probabilités, et la mettre à jour à chaque étape. De plus, on peut utiliser la géométrie des plongements pour tirer les entités dans une région donnée de l'espace, ce qui permettrait d'augmenter la spécificité des données et donc de la taxonomie extraite – il s'agirait en fait d'adapter la méthode expressive présentée à la section \ref{subsec:texp-clustering} au cas où l'on n'ait pas accès au graphe complet.


\paragraph{Extraction de taxonomie expressive}


Notre méthode d'extraction d'axiomes présente plusieurs limites : d'une part, les axiomes atomiques sont limités et laissent de côté les relations inverses, la composition de relations, les restrictions universelles, etc. D'autre part, on combine à chaque étape un axiome (complexe ou non) avec un atome : on ne peut donc pas combiner un axiome complexe avec un autre axiome complexe, ce qui interdit par exemple des axiomes de la forme $(A \land B) \lor (C \land D)$. Il serait également intéressant d'expérimenter d'autres approches pour l'extraction d'axiomes : comme l'espace de recherche est un sous-ensemble d'entités de petite taille et sémantiquement cohérent, il devrait être possible d'employer des méthodes plus complexes et capables d'extraire des axiomes plus expressifs, comme \cite{vlog2019carral}.

Quant aux faiblesses des taxonomies expressives extraites par notre approche, elles ont été discutées à la section \ref{subsec:texp-reslts-limits} : les axiomes extraits sont inégalement informatifs, parfois redondants ou trop spécifiques. La piste d'amélioration la plus évidente consiste à expérimenter des valeurs différentes pour les paramètres. Ceux-ci sont en effet nombreux, à chaque étape : on peut modifier les modalités du tirage aléatoire, la méthode de regroupement, l'ordre de parcours de l'arbre de clustering et sa profondeur maximale, le mode d'extraction (mono-niveau ou multi-niveaux), le nombre d'étapes et l'évolution du seuil $\delta$. Toutefois, pour systématiser une telle recherche, il est nécessaire de concevoir une méthode d'évaluation qualitative fiable des taxonomies produites. Pour ce faire, on peut envisager la démarche suivante : identifier des tâches externes susceptibles de tirer profit d'axiomes logiques (par exemple, typage automatique d'entités, réponse automatique à des questions, ou autre), et comparer, sur ces tâches, les performances d'un modèle utilisant seulement le graphe aux performances d'un modèle utilisant à la fois le graphe et la taxonomie extraite. On obtient ainsi une évaluation indirecte de cette taxonomie, qui permet de mesurer son utilité pratique.

% ce qui devrait autoriser l'emploi de méthodes 


Enfin, puisque l'on dispose de plongements vectoriels pour les entités, et d'axiomes logiques pour qualifier ces groupes, une direction de recherche intéressante serait de chercher une représentation vectorielle des axiomes logiques, afin d'obtenir une représentation unifiée pour les entités, les relations, les classes et les axiomes. 
Cela suppose de traduire géométriquement des opérateurs logiques tels que la négation, la conjonction ou la disjonction; ce problème est discuté par
\cite{gutierrez2018knowledge}, et une solution est esquissée par \cite{hao2019universal}.
